%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Sergio Olmos Pardo at 2018-03-18 23:06:38 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{geeRogers15,
	Abstract = {Regression models for correlated binary outcomes are commonly fit using a Generalized Estimating Equations (GEE) methodology. GEE uses the Liang and Zeger sandwich estimator to produce unbiased standard error estimators for regression coefficients in large sample settings even when the covariance structure is misspecified. The sandwich estimator performs optimally in balanced designs when the number of participants is large, and there are few repeated measurements. The sandwich estimator is not without drawbacks; its asymptotic properties do not hold in small sample settings. In these situations, the sandwich estimator is biased downwards, underestimating the variances. In this project, a modified form for the sandwich estimator is proposed to correct this deficiency. The performance of this new sandwich estimator is compared to the traditional Liang and Zeger estimator as well as alternative forms proposed by Morel, Pan and Mancl and DeRouen. The performance of each estimator was assessed with 95{\%} coverage probabilities for the regression coefficient estimators using simulated data under various combinations of sample sizes and outcome prevalence values with an Independence (IND), Autoregressive (AR) and Compound Symmetry (CS) correlation structure. This research is motivated by investigations involving rare-event outcomes in aviation data.},
	An = {PMC4793734},
	Author = {Rogers, Paul and Stoner, Julie},
	Date-Added = {2018-03-18 22:05:00 +0000},
	Date-Modified = {2018-03-18 22:05:23 +0000},
	Db = {PMC},
	Isbn = {2328-7292; 2328-7306},
	J1 = {Am J Appl Math Stat},
	Journal = {American journal of applied mathematics and statistics},
	Number = {6},
	Pages = {243--251},
	Title = {Modification of the Sandwich Estimator in Generalized Estimating Equations with Correlated Binary Outcomes in Rare Event and Small Sample Settings},
	Ty = {JOUR},
	U1 = {26998504{$[$}pmid{$]$}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4793734/},
	Volume = {3},
	Year = {2015},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4793734/}}

@article{geeHubbard,
	Author = {Alan E. Hubbard, Jennifer Ahern, Nancy L. Fleischer, Mark Van der Laan, Sheri A. Lippman, Nicholas Jewell, Tim Bruckner, William A. Satariano},
	Doi = {10.1097/EDE.0b013e3181caeb90},
	Journal = {Epidemiology},
	Pages = {467--474},
	Title = {To GEE or Not to GEE: Comparing Population Average and Mixed Models for Estimating the Associations Between Neighborhood Risk Factors and Health},
	Volume = {21},
	Year = {2010},
	Bdsk-Url-1 = {https://dx.doi.org/10.1097/EDE.0b013e3181caeb90}}

@article{geeSim,
	Abstract = {We consider the problem of calculating power and sample size for tests based on generalized estimating equations (GEE), that arise in studies involving clustered or correlated data (e.g., longitudinal studies and sibling studies). Previous approaches approximate the power of such tests using the asymptotic behavior of the test statistics under fixed alternatives. We develop a more accurate approach in which the asymptotic behavior is studied under a sequence of local alternatives that converge to the null hypothesis at root-m rate, where m is the number of clusters. Based on this approach, explicit sample size formulae are derived for Wald and quasi-score test statistics in a variety of GEE settings. Simulation results show that in the important special case of logistic regression with exchangeable correlation structure, previous approaches can inflate the projected sample size (to obtain nominal 90{\%} power using the Wald statistic) by over 10{\%}, whereas the proposed approach provides an accuracy of around 2{\%}.},
	An = {PMC3903421},
	Author = {Li, Zhigang and McKeague, Ian W},
	Date-Added = {2018-03-18 09:14:25 +0000},
	Date-Modified = {2018-03-18 09:15:07 +0000},
	Db = {PMC},
	Doi = {10.5705/ss.2011.081},
	Isbn = {1017-0405; 1996-8507},
	J1 = {Stat Sin},
	Journal = {Statistica Sinica},
	Month = {01},
	Number = {1},
	Pages = {231--250},
	Title = {Power and Sample Size Calculations for Generalized Estimating Equations via Local Asymptotics},
	Ty = {JOUR},
	U1 = {24478568{$[$}pmid{$]$}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3903421/},
	Volume = {23},
	Year = {2013},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3903421/},
	Bdsk-Url-2 = {https://dx.doi.org/10.5705/ss.2011.081}}

@article{simulation13,
	Abstract = {Simulation studies allow researchers to answer specific questions about data analysis, statistical power, and best-practices for obtaining accurate results in empirical research. Despite the benefits that simulation research can provide, many researchers are unfamiliar with available tools for conducting their own simulation studies. The use of simulation studies need not be restricted to researchers with advanced skills in statistics and computer programming, and such methods can be implemented by researchers with a variety of abilities and interests. The present paper provides an introduction to methods used for running simulation studies using the R statistical programming environment and is written for individuals with minimal experience running simulation studies or using R. The paper describes the rationale and benefits of using simulations and introduces R functions relevant for many simulation studies. Three examples illustrate different applications for simulation studies, including (a) the use of simulations to answer a novel question about statistical analysis, (b) the use of simulations to estimate statistical power, and (c) the use of simulations to obtain confidence intervals of parameter estimates through bootstrapping. Results and fully annotated syntax from these examples are provided.},
	An = {PMC4110976},
	Author = {Hallgren, Kevin A},
	Date-Added = {2018-03-18 01:18:01 +0000},
	Date-Modified = {2018-03-18 08:55:30 +0000},
	Db = {PMC},
	Isbn = {1913-4126},
	J1 = {Tutor Quant Methods Psychol},
	Journal = {Tutorials in quantitative methods for psychology},
	Number = {2},
	Pages = {43--60},
	Title = {Conducting Simulation Studies in the R Programming Environment},
	Ty = {JOUR},
	U1 = {25067989{$[$}pmid{$]$}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4110976/},
	Volume = {9},
	Year = {2013},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4110976/}}

@article{conjugate,
	Adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	Adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170906288L},
	Archiveprefix = {arXiv},
	Author = {{Lee}, J.~Y.~L. and {Green}, P.~J. and {Ryan}, L.~M.},
	Eprint = {1709.06288},
	Journal = {ArXiv e-prints},
	Keywords = {Statistics - Methodology},
	Month = sep,
	Primaryclass = {stat.ME},
	Title = {{Conjugate generalized linear mixed models for clustered data}},
	Year = 2017}

@article{robin18,
	Abstract = {Abstract Data in medical sciences often have a hierarchical structure with lower level units (e.g. children) nested in higher level units (e.g. departments). Several specific but frequently studied settings, mainly in longitudinal and family research, involve a large number of units that tend to be quite small, with units containing only one element referred to as singletons. Regardless of sparseness, hierarchical data should be analyzed with appropriate methodology such as, for example linear‐mixed models. Using a simulation study, based on the structure of a data example on Ceftriaxone consumption in hospitalized children, we assess the impact of an increasing proportion of singletons (0--95\%), in data with a low, medium, or high intracluster correlation, on the stability of linear‐mixed models parameter estimates, confidence interval coverage and F test performance. Some techniques that are frequently used in the presence of singletons include ignoring clustering, dropping the singletons from the analysis and grouping the singletons into an artificial unit. We show that both the fixed and random effects estimates and their standard errors are stable in the presence of an increasing proportion of singletons. We demonstrate that ignoring clustering and dropping singletons should be avoided as they come with biased standard error estimates. Grouping the singletons into an artificial unit might be considered, although the linear‐mixed model performs better even when the proportion of singletons is high. We conclude that the linear‐mixed model is stable in the presence of singletons when both lower‐ and higher level sample sizes are fixed. In this setting, the use of remedial measures, such as ignoring clustering and grouping or removing singletons, should be dissuaded.},
	Author = {Robin Bruyndonckx and Niel Hens and Marc Aerts},
	Doi = {10.1002/bimj.201700025},
	Eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.201700025},
	Journal = {Biometrical Journal},
	Keywords = {F test, hierarchical data, intracluster correlation, performance characteristics, sparseness},
	Number = {1},
	Pages = {49-65},
	Title = {Simulation‐based evaluation of the linear‐mixed model in the presence of an increasing proportion of singletons},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201700025},
	Volume = {60},
	Year = {2018},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201700025},
	Bdsk-Url-2 = {https://dx.doi.org/10.1002/bimj.201700025}}

@misc{fitz,
	Address = {Boston},
	Author = {Garret Fitzmaurice},
	Howpublished = {\url{https://catalyst.harvard.edu/docs/biostatsseminar/Fitzmaurice_BSP-Workshop-Slides.pdf}},
	Institution = {Harvard School of Public Health},
	Note = {Presentation Slides},
	Title = {Overview of Methods for Analyzing Cluster-Correlated Data},
	Year = 2005}
